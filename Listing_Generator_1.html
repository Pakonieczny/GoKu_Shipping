<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Listing-Generator-1</title>
  <style>
    :root { --bg:#0b0d12; --card:#121624; --muted:#8b93a7; --text:#e9ecf5; --line:#242a3d; }
    body{ margin:0; font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Arial; background:var(--bg); color:var(--text); }
    .wrap{ padding:14px; display:grid; grid-template-columns: 420px 1fr; gap:14px; }
    .card{ background:var(--card); border:1px solid var(--line); border-radius:14px; padding:12px; }
    h1{ font-size:16px; margin:0 0 10px 0; }
    label{ display:block; font-size:12px; color:var(--muted); margin:10px 0 6px; }
    textarea, select, input{ width:100%; border-radius:10px; border:1px solid var(--line); background:#0e1220; color:var(--text); padding:10px; box-sizing:border-box; }
    textarea{ min-height:120px; resize:vertical; }
    .row{ display:flex; gap:8px; }
    .btn{ cursor:pointer; border-radius:12px; border:1px solid var(--line); padding:10px 12px; background:#0e1220; color:var(--text); }
    .btn:disabled{ opacity:0.5; cursor:not-allowed; }
    .muted{ color:var(--muted); font-size:12px; line-height:1.35; }
    .drop{
      border:1px dashed #3a4262; border-radius:14px; padding:12px; background:#0e1220;
      display:flex; gap:10px; align-items:center; justify-content:space-between;
    }
    .drop strong{ font-size:13px; }
    .preview-box{
      width:100%; height:280px; border-radius:14px; border:1px solid var(--line);
      background:#0b0d12; overflow:hidden; position:relative;
    }
    .preview-box img{ width:100%; height:100%; object-fit:contain; transform-origin:center; }
    .traits{ display:grid; grid-template-columns: 1fr 1fr; gap:8px; margin-top:10px; }
    .pill{ font-size:12px; border:1px solid var(--line); background:#0e1220; border-radius:999px; padding:8px 10px; color:var(--muted); }
    .grid{
      display:grid; grid-template-columns: repeat(4, minmax(220px, 1fr)); gap:12px;
    }
    .slot{ background:#0e1220; border:1px solid var(--line); border-radius:14px; padding:10px; }
    .slotTop{ display:flex; justify-content:space-between; align-items:center; gap:8px; margin-bottom:8px; }
    .slotTop b{ font-size:12px; color:var(--muted); }
    .slotPrev{ width:100%; height:190px; border-radius:12px; border:1px solid var(--line); background:#0b0d12; overflow:hidden; }
    .slotPrev img{ width:100%; height:100%; object-fit:contain; transform-origin:center; }
    .bar{ height:8px; border-radius:999px; background:#0b0d12; border:1px solid var(--line); overflow:hidden; margin-top:10px; }
    .bar > div{ height:100%; width:0%; background:#2b6cff; transition:width 120ms linear; }
    .small{ font-size:11px; color:var(--muted); margin-top:6px; white-space:nowrap; overflow:hidden; text-overflow:ellipsis; }
  </style>
</head>

<body>
  <div class="wrap">
    <!-- LEFT -->
    <div class="card">
      <h1>Listing-Generator-1</h1>
      <div class="muted">Upload a reference image → tune prompt/traits → generate 8 variations → auto-upload to Firebase.</div>

      <label>Reference image (drag/drop or pick)</label>
      <div class="drop" id="drop">
        <div>
          <strong id="refName">No image selected</strong>
          <div class="muted">Tip: large images work, but faster if you keep them &lt; ~2–3MB.</div>
        </div>
        <div class="row">
          <input id="file" type="file" accept="image/*" />
        </div>
      </div>

     <label>Charm macro (Image[1] truth source)</label>
      <div class="drop" id="charmDrop">
        <div>
          <strong id="charmName">No charm macro selected</strong>
          <div class="muted">Upload a sharp macro of the charm only (flat, legible engraving). Sent to OpenAI as Image[1].</div>
        </div>
        <div class="row">
          <input id="charmFile" type="file" accept="image/*" />
        </div>
      </div>

      <label>Charm macro preview (zoom + pan)</label>
      <div class="preview-box" id="charmPreview" style="height:200px;"></div>

      <label>Reference preview (zoom + pan)</label>
      <div class="preview-box" id="refPreview"></div>

      <label>Generative description (live editable)</label>
      <textarea id="prompt"></textarea>

      <label>Model (Images API)</label>
      <select id="model">
        <option value="gpt-image-1.5">gpt-image-1.5 (if enabled)</option>
        <option value="gpt-image-1">gpt-image-1</option>
      </select>

      <label>Final charm size (px) (postprocess)</label>
      <div class="row">
        <input id="finalCharmTargetPx" type="range" min="8" max="24" step="1" value="14" />
        <input id="finalCharmTargetPxVal" type="text" value="14" style="width:86px;" />
      </div>
      <div class="muted">Sets the FINAL charm height in pixels after AI placement (stable, proportional control).</div>

      <div class="row" style="margin-top:10px;">
        <button class="btn" id="gen8">Generate 8</button>
        <button class="btn" id="clear">Clear</button>
      </div>

      <label>Selected traits (template → randomized per slot)</label>
      <div class="traits" id="traitsBox"></div>
    </div>

    <!-- RIGHT -->
    <div class="card">
      <div class="row" style="justify-content:space-between; align-items:center;">
        <h1 style="margin:0;">Generated images (8)</h1>
        <div class="muted" id="status">Idle</div>
      </div>
      <div class="grid" id="grid"></div>
    </div>
  </div>

  <!-- Firebase (same style as shipping-1 uses: compat init + modular storage/auth) -->
  <script src="https://www.gstatic.com/firebasejs/9.23.0/firebase-app-compat.js"></script>
  <script src="https://www.gstatic.com/firebasejs/9.23.0/firebase-auth-compat.js"></script>
  <script src="https://www.gstatic.com/firebasejs/9.23.0/firebase-firestore-compat.js"></script>

  <script type="module">
   import { initializeApp, getApp } from "https://www.gstatic.com/firebasejs/9.23.0/firebase-app.js";
   import { getStorage, ref, uploadBytesResumable, getDownloadURL } from "https://www.gstatic.com/firebasejs/9.23.0/firebase-storage.js";
   import { getAuth, signInAnonymously as modSignInAnonymously, onAuthStateChanged as modOnAuthStateChanged } from "https://www.gstatic.com/firebasejs/9.23.0/firebase-auth.js";


    // --- Netlify functions base ---
    const functionsBaseUrl = `${window.location.origin}/.netlify/functions`;

    // --- Firebase config (matches shipping-1 patterns) ---
    const firebaseConfig = {
      apiKey: "AIzaSyBXhQLsYRa4i0bX1TPTRiElF9Zjy5vSHlA",
      authDomain: "gokudatabase.firebaseapp.com",
      projectId: "gokudatabase",
      storageBucket: "gokudatabase.firebasestorage.app",
      messagingSenderId: "1078662308113",
      appId: "1:1078662308113:web:41df0e5d229ff2af7a6cb0"
    };
    firebase.initializeApp(firebaseConfig);
    // ✅ IMPORTANT: use COMPAT auth so COMPAT firestore (window.db) has permissions
    try {
      const cred = await firebase.auth().signInAnonymously();
      console.log("Anon auth ✔", cred?.user?.uid);
    } catch (e) {
      console.error("Anon auth ❌", e);
    }

    window.db = firebase.firestore();

    // modular twin (same approach as shipping-1 resumable uploader)
    let modApp;
    try { modApp = getApp(); } catch { modApp = initializeApp(firebase.app().options); }
    const storage = getStorage(modApp);
    const modAuth = getAuth(modApp);

    // Gate specifically for Storage (modular) so request.auth is never null in Storage rules
    async function ensureStorageSignedIn() {
      if (modAuth.currentUser) return modAuth.currentUser;
      try { await modSignInAnonymously(modAuth); } catch (_) {}

      return await new Promise((resolve, reject) => {
        const t = setTimeout(() => reject(new Error("Modular auth not ready. Enable Anonymous sign-in in Firebase Auth.")), 8000);
        const unsub = modOnAuthStateChanged(modAuth, async (u) => {
          if (!u) return;
          clearTimeout(t);
          unsub();
          try { await u.getIdToken(); } catch (_) {}
          resolve(u);
        });
      });
    }

    // --- UI State ---
    const fileEl = document.getElementById("file");
    const dropEl = document.getElementById("drop");
    const refNameEl = document.getElementById("refName");
    const refPreviewEl = document.getElementById("refPreview");
    const promptEl = document.getElementById("prompt");
    const modelEl = document.getElementById("model");
    const finalCharmTargetPxEl = document.getElementById("finalCharmTargetPx");
    const finalCharmTargetPxValEl = document.getElementById("finalCharmTargetPxVal");
    const gen8Btn = document.getElementById("gen8");
    const clearBtn = document.getElementById("clear");
    const gridEl = document.getElementById("grid");
    const statusEl = document.getElementById("status");
    const charmFileEl = document.getElementById("charmFile");
    const charmDropEl = document.getElementById("charmDrop");
    const charmNameEl = document.getElementById("charmName");
    const charmPreviewEl = document.getElementById("charmPreview");
    const traitsBox = document.getElementById("traitsBox");

    let referenceDataUrl = null;
    let referenceStoragePath = null;     // NEW: small identifier sent to background function
    let referenceDownloadUrl = null;     // NEW: optional, kept for debugging/inspection
    let charmMacroDataUrl = null;
    let charmMacroStoragePath = null;
    let charmMacroDownloadUrl = null;
    let slots = [];

    // Keep UI slider + text in sync (NEW: integer px target)
    function clampNum(n, lo, hi){ return Math.max(lo, Math.min(hi, n)); }
    function readFinalCharmTargetPx(){
      const raw = parseInt(finalCharmTargetPxEl?.value || "14", 10);
      const v = Number.isFinite(raw) ? raw : 14;
      return Math.round(clampNum(v, 8, 24));
    }
    function syncFinalCharmTargetPxUI(v){
      const x = String(Math.round(v));
      if (finalCharmTargetPxEl) finalCharmTargetPxEl.value = x;
      if (finalCharmTargetPxValEl) finalCharmTargetPxValEl.value = x;
    }
    if (finalCharmTargetPxEl && finalCharmTargetPxValEl){
      finalCharmTargetPxEl.addEventListener("input", ()=> syncFinalCharmTargetPxUI(readFinalCharmTargetPx()));
      finalCharmTargetPxValEl.addEventListener("change", ()=>{
        const raw = parseInt(finalCharmTargetPxValEl.value || "14", 10);
        const v = Number.isFinite(raw) ? raw : 14;
        syncFinalCharmTargetPxUI(clampNum(v, 8, 24));
      });
      syncFinalCharmTargetPxUI(readFinalCharmTargetPx());
    }

    // Trait defs (Etsy-friendly: clean necklines, pastel/neutral palette, jewelry-forward)
    const TRAITS = {
            skin: [
              "medium",
              "tan",
              "very tan",
              "deep",
              "very deep",
              "dark"
            ],
            wardrobe: [
              // Tops
              "linen button-down shirt",
              "cotton poplin shirt",
              "ribbed knit tank",
              "silky camisole",
              "classic crewneck tee",
              "soft scoop-neck tee",
              "fitted long-sleeve top",
              "mock-neck top",
              "lightweight turtleneck",
              "wrap blouse",
              "peasant blouse subtle texture",
              "satin blouse matte sheen",

              // Knitwear
              "chunky knit sweater",
              "fine-gauge knit sweater",
              "cardigan open front",
              "cropped cardigan",
              "cashmere pullover",
              "cable knit sweater subtle",

              // Outer layers
              "blazer over neutral top",
              "cropped blazer",
              "soft trench coat open",
              "lightweight wool coat open",
              "denim jacket light wash",
              "tailored vest over top",

              // Dresses (still good for neck/collarbone crops)
              "slip dress",
              "square-neck dress",
              "ribbed knit dress",
              "wrap dress solid",
              "minimal sundress"
              ],

            wardrobeColor: [
              // Neutrals that make gold pop
              "pale taupe",
              "warm beige",
              "oatmeal",
              "ivory",
              "soft cream",
              "stone",
              "mushroom",
              "warm greige",
              "light caramel",

              // Pastels that stay punchy-neutral
              "sage",
              "dusty olive",
              "misty blue",
              "powder blue",
              "soft periwinkle",
              "muted lavender",
              "dusty lilac",
              "blush pink",
              "muted rose",
              "soft peach",
              "buttercream",
              "pistachio",
              "seafoam"
              ],

            backdrop: [
              "soft peach studio backdrop",
              "warm sand studio backdrop",
              "misty blue studio backdrop",
              "pale lilac studio backdrop",
              "cream paper seamless backdrop",
              "warm beige gradient backdrop",
              "muted pastel colorwash backdrop",
              "airy off-white lifestyle wall backdrop"
            ],

            backgroundAccent: [
              "no accent",
              "subtle tonal gradient",
              "very soft vignette",
              "faint paper texture",
              "gentle studio falloff"
            ],

            lighting: [
              "soft diffused daylight window light",
              "large softbox studio light gentle shadows",
              "north-facing window light airy highlights",
              "two-softbox wrap light minimal contrast",
              "beauty-dish softened with diffusion",
              "overcast daylight look clean neutral"
            ],

            colorGrade: [
              "punchy-neutral pastel grade",
              "warm editorial pastel grade",
              "clean creamy highlights low saturation",
              "soft contrast with preserved skin texture",
              "neutral whites with warm metal emphasis"
            ],

            stylingMood: [
              "minimal editorial",
              "clean lifestyle",
              "soft romantic pastel",
              "modern neutral",
              "quiet luxury"
            ],

            makeup: [
              "no-makeup makeup natural",
              "soft matte neutral makeup",
              "dewy skin minimal makeup",
              "barely-there blush natural lip",
              "clean editorial minimal makeup"
            ],

            hair: [
              "loose waves behind shoulders",
              "sleek straight hair tucked behind ear",
              "low bun clean neckline",
              "low ponytail clean neckline",
              "half-up style clear collarbone"
            ],

            pose: [
              "shoulders relaxed straight-on",
              "shoulders relaxed, 2/3 left turn subtle",
              "shoulders relaxed, 2/3 right turn subtle"
            ],

            // Pass A: still place the charm clearly, but KEEP the crop ultra-tight and zoomed.
            cameraPlacement: [
              "Only show upper bust + collarbone close crop, TOP EDGE cuts at mid-neck (no jawline, no chin, no face), necklace centered, 120mm"
            ],

            // Pass B: final framing MUST be bust/collarbone only.
            cameraFinal: [
              "Only show upper bust + collarbone close crop, TOP EDGE cuts at mid-neck (no jawline, no chin, no face), necklace centered, 120mm"
            ],

              // lens look (perspective/compression)
            lensLook: [
              "120mm portrait close crop realistic"

            ],

            textureRules: [
              "no logos",
              "no busy patterns",
              "no jewelry besides the necklace",
              "fabric texture subtle only",
              "keep neckline unobstructed"
            ]
    };

    // -------------------------
    // Charm sizing control (hard numeric plan)
    // -------------------------
    // TRUE DESIRED final size (what you actually want to see in the final image)
    const CHARM_FINAL_PX_TRUE = { min: 12, max: 16, target: 14 };

    // MODEL OVERSCALE COMPENSATION:
    // The model tends to render the charm ~1.5–2.0x too large even when given px targets.
    // So we instruct a *smaller* px window (bias-compensated) to land at TRUE 12–16px.
    // These are inverse multipliers (smaller = stronger shrink).
    const CHARM_INV_OVERSCALE_BASE = {
      mm120: 0.35,
      macro: 0.48
    };
    const CHARM_INV_OVERSCALE_ZOOM = {
      wide: 0.75,    // chest-up tends to overscale more → instruct smaller
      medium: 0.9,
      tight: 1.00
    };

    // Pass A should keep the charm larger to preserve engraving detail while placing.
    const CHARM_A_MULT = 1.25;

    // -------------------------
    // Deterministic final framing (server-side, applied to OUTPUT only)
    // -------------------------
    const FINAL_FRAME_ZOOM = 1.12;  // increase to zoom in more (e.g. 1.65)
    const FINAL_ANCHOR_X = 0.50;
    const FINAL_ANCHOR_Y = 0.45;   // shift crop UP so necklace lands lower in the final frame

    function parseLensMm(lensLook = "") {
      const s = String(lensLook).toLowerCase();
      if (s.includes("120mm")) return 120;
      return 120;
    }

    function parseFinalZoomGroup(cameraFinal = "") {
      const s = String(cameraFinal).toLowerCase();
      // more zoomed out framing groups
      if (s.includes("chest-up")) return "wide";
      if (s.includes("neck/jawline")) return "medium";
      if (s.includes("neck + collarbone")) return "tight";
      return "medium";
    }

    function clamp(n, lo, hi){ return Math.max(lo, Math.min(hi, n)); }

    function charmPlanFromTraits(traits, stage /* "placement" | "final" */) {
      const lensMm = parseLensMm(traits?.lensLook);
      const zoomGroup = parseFinalZoomGroup(traits?.cameraFinal);

      // --- bias-compensated instruction window ---
      const lensKey =
        (String(traits?.lensLook || "").toLowerCase().includes("macro")) ? "macro" :
        (lensMm >= 120) ? "mm120" : "mm120";

      const invBase = CHARM_INV_OVERSCALE_BASE[lensKey] ?? 0.50;
      const invZoom = CHARM_INV_OVERSCALE_ZOOM[zoomGroup] ?? 1.12;
      // Final inverse multiplier applied to TRUE targets to produce MODEL-INSTRUCTION targets
      const invOverscale = clamp(invBase * invZoom, 0.32, 0.70);

      // TRUE target (what you want)
      const finalTrue = {
        minPx: CHARM_FINAL_PX_TRUE.min,
        maxPx: CHARM_FINAL_PX_TRUE.max,
        targetPx: CHARM_FINAL_PX_TRUE.target,
      };

      // MODEL-INSTRUCTION target (what we tell the model)
      const finalInstr = {
        minPx: Math.round(finalTrue.minPx * invOverscale),
        maxPx: Math.round(finalTrue.maxPx * invOverscale),
        targetPx: Math.round(finalTrue.targetPx * invOverscale),
      };

      // Pass A instruction target (larger for engraving placement fidelity)
      const placementInstr = {
        minPx: Math.round(finalInstr.minPx * CHARM_A_MULT),
        maxPx: Math.round(finalInstr.maxPx * CHARM_A_MULT),
        targetPx: Math.round(finalInstr.targetPx * CHARM_A_MULT),
      };

      return {
        stage,
        lensMm,
        zoomGroup,
        lensKey,
        invOverscale,          // how much smaller we instruct vs TRUE targets
        finalTrue,             // your real desired window (12–16px)
        finalInstr,            // bias-compensated instruction window
        ...(stage === "placement" ? { instr: placementInstr } : { instr: finalInstr }),
      };
    }


       function pick(arr, label="trait"){
       if (!Array.isArray(arr) || arr.length === 0) {
         console.warn(`pick(): TRAITS.${label} missing or empty`, arr);
         return "";
       }
       return arr[Math.floor(Math.random() * arr.length)];
       }
    function makeTraits(){
      return {
        skin: pick(TRAITS.skin, "skin"),
        cameraPlacement: pick(TRAITS.cameraPlacement, "cameraPlacement"),
        cameraFinal: pick(TRAITS.cameraFinal, "cameraFinal"),
        wardrobe: pick(TRAITS.wardrobe, "wardrobe"),
        wardrobeColor: pick(TRAITS.wardrobeColor, "wardrobeColor"),
        backdrop: pick(TRAITS.backdrop, "backdrop"),
        backgroundAccent: pick(TRAITS.backgroundAccent, "backgroundAccent"),
        lighting: pick(TRAITS.lighting, "lighting"),
        colorGrade: pick(TRAITS.colorGrade, "colorGrade"),
        stylingMood: pick(TRAITS.stylingMood, "stylingMood"),
        makeup: pick(TRAITS.makeup, "makeup"),
        hair: pick(TRAITS.hair, "hair"),
        pose: pick(TRAITS.pose, "pose"),
        lensLook: pick(TRAITS.lensLook, "lensLook"),
        textureRules: pick(TRAITS.textureRules, "textureRules"),
      };
    }

    // Default prompt (edit freely)
    promptEl.value =
    `CRITICAL: This is a standard fashion product photo. Do not add nudity. Always keep the subject modest.

    PROCESS ORDER (NON-NEGOTIABLE)
    • First: generate the model variation + necklace (no charm).
    • Second: add the charm from Image[1] onto the necklace (placement + hardware correctness).
    • Third: final charm downscale is applied AFTER generation as a deterministic postprocess (no redraw). Do not “fix” size by changing engraving.

    SIZE RULE (NON-NEGOTIABLE)
    • Place the charm slightly LARGE during the “add charm” step to preserve micro-engraving fidelity.
    • Final size is applied as a postprocess downscale of the charm pixels only (no regeneration, no re-engraving).
    • Do NOT thicken, simplify, or redraw engraving to solve size.

    ZOOM RANGE CLAMP (NON-NEGOTIABLE)
    • The visible necklace span (left-to-right chain) should fill roughly 97%–100% of the image width.
    • Final framing MUST be upper bust + collarbones only.
    • TOP CROP RULE: the top edge must cut at the base of the neck.
    • BOTTOM CROP RULE: bottom edge must be upper bust only.
    • Keep the pendant centered in the frame. Never show any part of the head and face.
    • Keep the neck short and proportional.

    INPUT IMAGES (ORDER MATTERS)
    • Image[0] = base model photo (necklace position + scene + camera)
    • Image[1] = charm macro (pixel-truth source for charm silhouette + engraving)

    TRAITS OVERRIDE (NON-NEGOTIABLE)
    • A "Traits:" block will be appended at the end of this prompt.
    • Treat every trait line as a hard requirement to apply literally (not suggestions, not metadata).
    • If any style text above conflicts with Traits, Traits win for: skin, camera framing, wardrobe, backdrop, lighting.
    • Exception: jewelry locks always win (necklace + charm fidelity rules never change).
    • Do not average traits. Do not ignore traits. Do not partially apply traits. Apply all traits.

    TASK (CRITICAL)
      1.  Place Image[1] as the pendant on the necklace in Image[0]. Treat Image[1] like a literal decal/insert.
      2.  Do not redraw, regenerate, re-engrave, “improve,” clean up, simplify, stylize, or reinterpret the charm.
      3.  The Charm must be very flat and thin, without any noticeable potrusions and the engraving is to be superficial.
      4.  Engraving rule: preserve every engraving stroke exactly as in Image[1]. No stroke loss, no stroke merging, no thickening, no line cleanup, no mirrored text, no invented marks.
      5.  Allowed charm edits (only): tiny exposure/white-balance shift to match scene lighting + a subtle contact shadow under the charm + mild specular highlight alignment. No geometry changes.
      6.  BACKGROUND_DIAL: pastel studio backdrop in soft peach 
      7.  LIGHTING_DIAL: window light, airy highlights Editorial Etsy portrait (neck + collarbone close crop). One adult female model with natural skin texture, realistic pores, no heavy retouching. Tight framing keeps neck/collarbone clear so the necklace stations are fully visible. Recreate the exact single-strand satellite chain necklace from the reference—identical bead station shape/size/spacing, identical chain link size/shape, identical drape/tension, identical placement on the neck; warm yellow gold tone with crisp specular highlights. Clean modern pastel grading, soft peach backdrop, powder blue white-tee look.  

    ENGRAVING COLOR (NON-NEGOTIABLE)
    • Engraving must remain a bright metal tone consistent with the charm’s metal (warm yellow).
    • Engraving lines may be only slightly darker than the surrounding metal due to shading.
    • Engraving must be filled-in exactly like in Image[0]

    FOCUS (REALISM PRIORITY)
    • High-res, sharp focus on beads + links + charm surface. Moderate depth of field.
    • If the charm becomes illegible, DO NOT alter engraving. Use camera/zoom changes ONLY at the end, after charm is locked.
    • Jump ring must be closed + correctly connected to charm and chain; no floating, no broken links.

    NECKLACE LOCK
    Single strand only. Station count/spacing + link geometry + drape must remain consistent with Image[0]. No added jewelry.

    LOOK
    Soft peach backdrop, pale taupe styling, punchy-neutral pastel grade. Natural pores, no plastic skin. Jewelry tack sharp.

    HARD FAIL CONDITIONS
    - Warped links, doubled chain, altered charm outline, missing strokes, simplified engraving, blur/smear on charm, any engraving rendered as grey/dark grey/dark brown/black or “filled, second strand, altered spacing, thicker chain, neon colors, plastic skin, warped links.
    - Charm Engraving must never appear grey, dark grey, dark brown, black, charcoal, ink-like, oxidized, soot-filled, painted, or enamel-filled.
    - Never show model jawline, chin, face.`;


    // --- Zoom + pan listeners ---
    function attachZoomPan(box){
      let isMouseDown = false;
      let dragStartX = 0, dragStartY = 0;
      let lastX = 0, lastY = 0;

      box.addEventListener("wheel", (ev) => {
        const img = box.querySelector("img");
        if (!img) return;
        ev.preventDefault();
        let s = parseFloat(img.dataset.scale) || 1;
        let ox = parseFloat(img.dataset.offsetX) || 0;
        let oy = parseFloat(img.dataset.offsetY) || 0;
        if (ev.deltaY < 0) s *= 1.1;
        else {
          s /= 1.1;
          if (s <= 1) { s = 1; ox = 0; oy = 0; }
        }
        if (s > 8) s = 8;
        img.dataset.scale = s;
        img.dataset.offsetX = ox;
        img.dataset.offsetY = oy;
        img.style.transform = `translate(${ox}px, ${oy}px) scale(${s})`;
      }, { passive:false });

      box.addEventListener("mousedown", (ev) => {
        const img = box.querySelector("img");
        if (!img) return;
        isMouseDown = true;
        dragStartX = ev.clientX;
        dragStartY = ev.clientY;
        lastX = parseFloat(img.dataset.offsetX) || 0;
        lastY = parseFloat(img.dataset.offsetY) || 0;
      });
      window.addEventListener("mouseup", () => { isMouseDown = false; });
      window.addEventListener("mousemove", (ev) => {
        const img = box.querySelector("img");
        if (!img || !isMouseDown) return;
        const dx = ev.clientX - dragStartX;
        const dy = ev.clientY - dragStartY;
        const ox = lastX + dx;
        const oy = lastY + dy;
        img.dataset.offsetX = ox;
        img.dataset.offsetY = oy;
        const s = parseFloat(img.dataset.scale) || 1;
        img.style.transform = `translate(${ox}px, ${oy}px) scale(${s})`;
      });
    }

    function setPreview(box, dataUrl){
      box.innerHTML = `<img src="${dataUrl}" data-scale="1" data-offsetX="0" data-offsetY="0" />`;
      attachZoomPan(box);
    }

    async function fileToDataUrl(file, opts = {}){
      const {
        maxDim = 5000,          // keep detail, shrink payload
        mime = "image/png",
        quality = 1.0,

        // --- NEW: deterministic framing lock (crop -> resize) ---
        outW = null,            // e.g. 1024
        outH = null,            // e.g. 1024
        frameZoom = 1.12,        // e.g. 1.12 means "zoom in" by cropping to 1/1.12 area
        anchorX = 0.5,          // 0..1 crop center X
        anchorY = 0.6,          // 0..1 crop center Y (biased lower to favor necklace)
      } = opts;

      const clamp01 = (v) => Math.max(0, Math.min(1, Number(v)));
      const wantFrameLock =
        Number.isFinite(Number(outW)) &&
        Number.isFinite(Number(outH)) &&
        Number(outW) > 0 &&
        Number(outH) > 0;

      // Modern path
      try {
        const bmp = await createImageBitmap(file);
        const w = bmp.width, h = bmp.height;
        let tw, th;
        let sx = 0, sy = 0, sw = w, sh = h;

        if (wantFrameLock) {
          // 1) crop to target aspect
          const targetAR = Number(outW) / Number(outH);
          const srcAR = w / h;
          if (srcAR > targetAR) {
            sh = h;
            sw = Math.max(1, Math.round(h * targetAR));
          } else {
            sw = w;
            sh = Math.max(1, Math.round(w / targetAR));
          }

          // 2) apply zoom (smaller crop => more zoom)
          const z = Math.max(1, Number(frameZoom) || 1);
          sw = Math.max(1, Math.round(sw / z));
          sh = Math.max(1, Math.round(sh / z));

          // 3) anchor (biased slightly lower by default)
          const ax = clamp01(anchorX);
          const ay = clamp01(anchorY);
          const cx = w * ax;
          const cy = h * ay;
          sx = Math.round(cx - sw / 2);
          sy = Math.round(cy - sh / 2);
          sx = Math.max(0, Math.min(w - sw, sx));
          sy = Math.max(0, Math.min(h - sh, sy));

          tw = Math.max(1, Math.round(Number(outW)));
          th = Math.max(1, Math.round(Number(outH)));
        } else {
          const scale = Math.min(1, maxDim / Math.max(w, h));
          tw = Math.max(1, Math.round(w * scale));
          th = Math.max(1, Math.round(h * scale));
        }

        const canvas = document.createElement("canvas");
        canvas.width = tw;
        canvas.height = th;

        const ctx = canvas.getContext("2d", { alpha: false });
        ctx.imageSmoothingEnabled = true;
        ctx.imageSmoothingQuality = "high";
       if (wantFrameLock) {
          ctx.drawImage(bmp, sx, sy, sw, sh, 0, 0, tw, th);
        } else {
          ctx.drawImage(bmp, 0, 0, tw, th);
        }
        // Important: toDataURL on jpeg dramatically reduces size
        return canvas.toDataURL(mime, quality);
      } catch (_) {
        // Fallback: FileReader -> Image -> canvas
        const dataUrl = await new Promise((resolve, reject)=>{
          const reader = new FileReader();
          reader.onload = ()=> resolve(reader.result);
          reader.onerror = reject;
          reader.readAsDataURL(file);
        });

        const img = await new Promise((resolve, reject)=>{
          const i = new Image();
          i.onload = ()=> resolve(i);
          i.onerror = reject;
          i.src = dataUrl;
        });

        const w = img.naturalWidth || img.width;
        const h = img.naturalHeight || img.height;
        let tw, th;
        let sx = 0, sy = 0, sw = w, sh = h;

        const clamp01 = (v) => Math.max(0, Math.min(1, Number(v)));
        const wantFrameLock =
          Number.isFinite(Number(outW)) &&
          Number.isFinite(Number(outH)) &&
          Number(outW) > 0 &&
          Number(outH) > 0;

        if (wantFrameLock) {
          const targetAR = Number(outW) / Number(outH);
          const srcAR = w / h;
          if (srcAR > targetAR) {
            sh = h;
            sw = Math.max(1, Math.round(h * targetAR));
          } else {
            sw = w;
            sh = Math.max(1, Math.round(w / targetAR));
          }

          const z = Math.max(1, Number(frameZoom) || 1);
          sw = Math.max(1, Math.round(sw / z));
          sh = Math.max(1, Math.round(sh / z));

          const ax = clamp01(anchorX);
          const ay = clamp01(anchorY);
          const cx = w * ax;
          const cy = h * ay;
          sx = Math.round(cx - sw / 2);
          sy = Math.round(cy - sh / 2);
          sx = Math.max(0, Math.min(w - sw, sx));
          sy = Math.max(0, Math.min(h - sh, sy));

          tw = Math.max(1, Math.round(Number(outW)));
          th = Math.max(1, Math.round(Number(outH)));
        } else {
          const scale = Math.min(1, maxDim / Math.max(w, h));
          tw = Math.max(1, Math.round(w * scale));
          th = Math.max(1, Math.round(h * scale));
        }

        const canvas = document.createElement("canvas");
        canvas.width = tw;
        canvas.height = th;

        const ctx = canvas.getContext("2d", { alpha: false });
        ctx.imageSmoothingEnabled = true;
        ctx.imageSmoothingQuality = "high";
        if (wantFrameLock) {
          ctx.drawImage(img, sx, sy, sw, sh, 0, 0, tw, th);
        } else {
          ctx.drawImage(img, 0, 0, tw, th);
        }
        return canvas.toDataURL(mime, quality);
      }
    }

    // Drag/drop
    dropEl.addEventListener("dragover", (e)=>{ e.preventDefault(); dropEl.style.borderColor="#2b6cff"; });
    dropEl.addEventListener("dragleave", ()=>{ dropEl.style.borderColor="#3a4262"; });
    dropEl.addEventListener("drop", async (e)=>{
      e.preventDefault(); dropEl.style.borderColor="#3a4262";
      const f = e.dataTransfer.files?.[0];
      if (!f) return;
      await loadReference(f);
    });
    fileEl.addEventListener("change", async ()=>{
      const f = fileEl.files?.[0];
      if (!f) return;
      await loadReference(f);
    });

  // Charm macro drag/drop
    charmDropEl.addEventListener("dragover", (e)=>{ e.preventDefault(); charmDropEl.style.borderColor="#2b6cff"; });
    charmDropEl.addEventListener("dragleave", ()=>{ charmDropEl.style.borderColor="#3a4262"; });
    charmDropEl.addEventListener("drop", async (e)=>{
      e.preventDefault(); charmDropEl.style.borderColor="#3a4262";
      const f = e.dataTransfer.files?.[0];
      if (!f) return;
      await loadCharmMacro(f);
    });
    charmFileEl.addEventListener("change", async ()=>{
      const f = charmFileEl.files?.[0];
      if (!f) return;
      await loadCharmMacro(f);
    });

    // Helpers
    function b64ToBlob(b64, mime="image/png"){
      const bin = atob(b64);
      const len = bin.length;
      const bytes = new Uint8Array(len);
      for (let i=0;i<len;i++) bytes[i] = bin.charCodeAt(i);
      return new Blob([bytes], { type: mime });
    }

    function dataUrlToFile(dataUrl, filenameBase = "reference"){
      const m = /^data:([^;]+);base64,(.+)$/.exec(dataUrl || "");
      if (!m) throw new Error("Bad data URL");
      const mime = m[1];
      const b64 = m[2];
      const blob = b64ToBlob(b64, mime);
      const ext =
        mime.includes("jpeg") ? "jpg" :
        mime.includes("png") ? "png" :
        (mime.split("/")[1] || "bin");
      return new File([blob], `${filenameBase}.${ext}`, { type: mime });
    }

    // Upload with realtime progress
    async function uploadWithProgress(path, file, onProgress, opts = {}){
      // Ensure request.auth is present before Storage calls (Storage uses modular auth)
      await ensureStorageSignedIn();
      const storageRef = ref(storage, path);
      const task = uploadBytesResumable(storageRef, file, { contentType: file.type });
      await new Promise((resolve, reject) => {
        task.on("state_changed",
          (snap) => {
            if (!snap.totalBytes) return;
            onProgress?.(snap.bytesTransferred / snap.totalBytes);
          },
          reject,
          resolve
        );
      });
      const wantUrl = opts.returnDownloadUrl === true;
      if (!wantUrl) return null;

      // If you explicitly ask for a URL, try it — but READ rules may still deny it.
      try { return await getDownloadURL(storageRef); }
      catch (err) { throw err; }
    }

    async function loadReference(file){
      // NEW: upload reference to Firebase Storage so we never send base64 to Netlify background functions.
      refNameEl.textContent = file.name;

      // Ensure Storage auth is ready before any upload attempt
      await ensureStorageSignedIn();

      // prevent clicking Generate while reference is uploading
      gen8Btn.disabled = true;

      // reset any prior reference cache
      referenceDataUrl = null;
      referenceStoragePath = null;
      referenceDownloadUrl = null;

      try {
        // NEW: ensure auth is established before we attempt Storage upload
        statusEl.textContent = "Preparing reference…";
        // Preview + upload helper (NO crop/zoom). Just downscale to a sane maxDim.
        referenceDataUrl = await fileToDataUrl(file, {
          maxDim: 1024,
          mime: "image/png",
          quality: 1.0,
        });
        setPreview(refPreviewEl, referenceDataUrl);

        // Convert the resized dataURL into a File for Storage upload
        const refFile = dataUrlToFile(referenceDataUrl, "reference");

        // must match server allowlist prefix: listing-generator-1/reference/...
        const refId = `ref_${Date.now()}_${Math.random().toString(16).slice(2)}`;
        const ext = refFile.name.split(".").pop() || "jpg";
        referenceStoragePath = `listing-generator-1/reference/${refId}.${ext}`;

        statusEl.textContent = "Uploading reference… 0%";

        // IMPORTANT: upload the *reference* file to the *reference* path
        // Also: do NOT request a download URL here (avoid any read/metadata rule mismatch)
        referenceDownloadUrl = await uploadWithProgress(
          referenceStoragePath,
          refFile,
          (p) => {
            const pct = Math.max(0, Math.min(100, Math.round((p || 0) * 100)));
            statusEl.textContent = `Uploading reference… ${pct}%`;
          },
          { returnDownloadUrl: false }
        );

        statusEl.textContent = "Reference ready";
      } catch (e) {
        console.error(e);
        statusEl.textContent = `Reference error: ${e.message || e}`;
        // allow user to try again
        gen8Btn.disabled = false;
        throw e;
      } finally {
        // re-enable if we have a valid storage path
        if (referenceStoragePath) gen8Btn.disabled = false;
      }
    }

    async function loadCharmMacro(file){
    charmNameEl.textContent = file.name;
    await ensureStorageSignedIn();

    // prevent clicking Generate while charm macro is uploading
    gen8Btn.disabled = true;

    // reset any prior charm macro cache
    charmMacroDataUrl = null;
    charmMacroStoragePath = null;
    charmMacroDownloadUrl = null;

    try {
      statusEl.textContent = "Preparing charm macro…";
      // Keep more detail for macro (slightly higher quality)
      charmMacroDataUrl = await fileToDataUrl(file, { maxDim: 5000, mime: "image/png", quality: 1.00 });
      setPreview(charmPreviewEl, charmMacroDataUrl);

      // IMPORTANT: upload the ORIGINAL file bytes to avoid any canvas smoothing / re-encoding drift
      // (Preview can still use charmMacroDataUrl above.)
      const macroFile = file;

      const macroId = `charm_${Date.now()}_${Math.random().toString(16).slice(2)}`;
      const ext = macroFile.name.split(".").pop() || "jpg";
      // must match server allowlist prefix in openaiImageProxy-background.js
      charmMacroStoragePath = `listing-generator-1/charm-macro/${macroId}.${ext}`;

      statusEl.textContent = "Uploading charm macro… 0%";

      // IMPORTANT: do NOT request a download URL here (avoids read/metadata rule mismatch -> 403)
      charmMacroDownloadUrl = await uploadWithProgress(
        charmMacroStoragePath,
        macroFile,
        (p) => {
          const pct = Math.max(0, Math.min(100, Math.round((p || 0) * 100)));
          statusEl.textContent = `Uploading charm macro… ${pct}%`;
        },
        { returnDownloadUrl: false }
      );

      statusEl.textContent = "Charm macro ready";
    } catch (e) {
      console.error(e);
      statusEl.textContent = `Charm macro error: ${e.message || e}`;
      gen8Btn.disabled = false;
      throw e;
    } finally {
      // re-enable if reference is ready (charm macro is optional)
      if (referenceStoragePath) gen8Btn.disabled = false;
    }
  }

    // Grid
    function makeSlot(i){
      const el = document.createElement("div");
      el.className = "slot";
      el.innerHTML = `
        <div class="slotTop">
          <b>Slot ${i+1}</b>
          <button class="btn" data-reg="${i}">Regenerate</button>
        </div>
        <div class="slotPrev" id="prev_${i}"></div>
        <div class="bar"><div id="bar_${i}"></div></div>
        <div class="small" id="meta_${i}">—</div>
      `;
      return el;
    }

    function renderGrid(){
      gridEl.innerHTML = "";
      slots = Array.from({length:8}).map((_,i)=>({
        i,
        traits: makeTraits(),
        prompt: "",
        imageDataUrl: null,
        uploadUrl: null,
        uploading: false,
      }));
      slots.forEach((s)=> gridEl.appendChild(makeSlot(s.i)));

      // show trait template (first slot)
      renderTraits(slots[0].traits);

      // regen handler
      gridEl.querySelectorAll("button[data-reg]").forEach(btn=>{
        btn.addEventListener("click", async ()=>{
          const idx = Number(btn.getAttribute("data-reg"));
          await generateOne(idx);
        });
      });
    }

    function renderTraits(t){
      traitsBox.innerHTML = "";
      Object.entries(t).forEach(([k,v])=>{
        const d = document.createElement("div");
        d.className = "pill";
        d.textContent = `${k}: ${v}`;
        traitsBox.appendChild(d);
      });
    }

    function setBar(i, pct){
      const bar = document.getElementById(`bar_${i}`);
      if (bar) bar.style.width = `${Math.max(0, Math.min(100, pct))}%`;
    }

    function setMeta(i, txt){
      const m = document.getElementById(`meta_${i}`);
      if (m) m.textContent = txt;
    }

    function setSlotPreview(i, dataUrl){
      const box = document.getElementById(`prev_${i}`);
      if (!box) return;
      box.innerHTML = `<img src="${dataUrl}" data-scale="1" data-offsetX="0" data-offsetY="0" />`;
      attachZoomPan(box);
    }

    const JOBS_COLL = "ListingGenerator1Jobs";

    async function enqueueOpenAIImageJob(payload){
      // Background function: returns fast; work continues server-side.
      const resp = await fetch("/.netlify/functions/openaiImageProxy-background", {
        method: "POST",
        headers: { "Content-Type":"application/json" },
        body: JSON.stringify(payload)
      });

      // Background functions respond immediately; we only need a 2xx here.
      if (!resp.ok) {
        const raw = await resp.text().catch(()=> "");
        throw new Error(raw || `openaiImageProxy-background HTTP ${resp.status}`);
      }
    }

    function buildPrompt(base, traits, hasCharmMacro, stage /* "placement" | "final" */, charmPlan){
      const imageRoleBlock = hasCharmMacro ? [
        "INPUT IMAGES (ORDER MATTERS)",
        stage === "placement"
          ? "- Image[0]: reference photo (truth source for necklace placement + chain geometry + station spacing + metal tone + drape)."
          : "- Image[0]: pass-A composite (truth source: charm already placed/locked + necklace already correct).",
        "- Image[1]: charm macro (single truth source for charm silhouette + engraving; if any conflict, Image[1] wins for charm details).",
        "",
      ].join("\n") : "";

      const processOrder = [
        "PROCESS ORDER (DO NOT REORDER)",
        "1) Place charm + hardware first. Preserve macro engraving exactly.",
        "2) Confirm scale clamp (pixel height + on-screen %).",
        "3) ONLY AT THE END apply camera/lens/zoom instructions (no engraving redraw).",
        "",
      ].join("\n");

      // Apply all non-camera traits immediately (so wardrobe/backdrop/lighting happen),
      // but force camera instructions to appear LAST to reduce “camera-first” re-generation.
      const immediateTraits = [
        "TRAITS LOCK (APPLY NOW — obey exactly, do not average out or ignore)",
        `- skin tone: ${traits.skin}`,
        `- wardrobe: ${traits.wardrobe}`,
        `- wardrobe color: ${traits.wardrobeColor}`,
        `- backdrop: ${traits.backdrop}`,
        `- backdrop accent: ${traits.backgroundAccent}`,
        `- lighting: ${traits.lighting}`,
        `- color grade: ${traits.colorGrade}`,
        `- styling mood: ${traits.stylingMood}`,
        `- hair: ${traits.hair}`,
        `- makeup: ${traits.makeup}`,
        `- pose: ${traits.pose}`,
        `- rules: ${traits.textureRules}`,
        "",
      ].join("\n");

      const cameraLast = [
        "CAMERA + LENS (APPLY LAST — after charm is locked)",
        `- camera framing: ${stage === "placement" ? traits.cameraPlacement : traits.cameraFinal}`,
        `- lens look: ${traits.lensLook}`,
        "- focus: charm pendant + chain stations tack sharp; background softly blurred",
        "- zoom rule: do not zoom until charm is correct; never redraw engraving to compensate for zoom",
        "- HARD CROP GUARD: show only upper bust + collarbones; TOP EDGE cuts at mid-neck; absolutely no jawline/chin/face",
        "",
      ].join("\n");

      const stageBlock = stage === "placement"
        ? [
            "STAGE A (PLACEMENT LOCK)",
            "- Keep framing close enough that the charm is large/clear while placing it.",
            "- Do NOT zoom out in this stage.",
            "",
            "CHARM SIZE CONTROL (STAGE A — HARD NUMBERS, BIAS-COMPENSATED)",
            `- Lens: ${charmPlan?.lensMm}mm (${charmPlan?.lensKey}) | Framing: ${charmPlan?.zoomGroup}`,
            `- TRUE final goal later (Stage B): ${charmPlan?.finalTrue?.minPx}–${charmPlan?.finalTrue?.maxPx}px (target ${charmPlan?.finalTrue?.targetPx}px)`,
            `- Model overscale correction factor: ${charmPlan?.invOverscale}× (we instruct smaller to land at the TRUE goal)`,
            `- PLACE NOW (instruction target): charm bbox height ${charmPlan?.instr?.minPx}–${charmPlan?.instr?.maxPx}px (target ${charmPlan?.instr?.targetPx}px)`,
            "- If the charm still looks large, keep shrinking until it hits the instruction px window. Do not stop early.",
            "",

          ].join("\n")
        : [
            "STAGE B (FINAL CAMERA)",
            "- Start from Image[0] (pass-A composite). Treat charm + necklace as pixel-locked truth.",
            "- Do NOT alter charm silhouette, engraving strokes, jump ring connection, or necklace geometry.",
            "- Only adjust camera framing/zoom at the end per CAMERA + LENS block.",
            "",
            "CHARM SIZE CONTROL (STAGE B — FINAL HARD NUMBERS, BIAS-COMPENSATED)",
            `- TRUE required final size: charm bbox height ${charmPlan?.finalTrue?.minPx}–${charmPlan?.finalTrue?.maxPx}px (target ${charmPlan?.finalTrue?.targetPx}px)`,
            `- Instruction window (compensated): ${charmPlan?.instr?.minPx}–${charmPlan?.instr?.maxPx}px (target ${charmPlan?.instr?.targetPx}px)`,
            "- IMPORTANT: do NOT redraw engraving to satisfy size. Only adjust framing/zoom until charm reaches TRUE size.",
            //"- If output charm is still ~2× too large, shrink it again (repeat the reduction) until it lands inside TRUE window.",
            "",
          ].join("\n");

      return [
        imageRoleBlock,
        processOrder,
        stageBlock,
        immediateTraits,
        base,
        "",
        cameraLast,
      ].filter(Boolean).join("\n");
    }

    async function generateOne(i){
      // NEW: require uploaded reference path (no base64 sent to Netlify)
      if (!referenceStoragePath) throw new Error("No reference image selected (or reference upload not finished)");

      const slot = slots[i];
      slot.traits = makeTraits(); // new random traits per regeneration
      const hasCharm = !!charmMacroStoragePath;
      const baseText = promptEl.value.trim();
      renderTraits(slot.traits);

      const model = modelEl.value;
      const runId = `lg1_${Date.now()}_${Math.random().toString(16).slice(2)}`;
      const jobIdA = `${runId}_slot_${i+1}_A`;
      const jobIdB = `${runId}_slot_${i+1}_B`;
      const jobRefA = window.db.collection(JOBS_COLL).doc(jobIdA);
      const jobRefB = window.db.collection(JOBS_COLL).doc(jobIdB);
      let unsubA = null;
      let unsubB = null;

      setBar(i, 5);
      setMeta(i, hasCharm ? "Queued (Pass A)…" : "Queued…");

      try {
        // ---------- Single-pass fallback (no charm macro) ----------
        if (!hasCharm) {
          const fullPrompt = buildPrompt(baseText, slot.traits, false, "final");
          slot.prompt = fullPrompt;

          let unsub = null;
          const jobRef = window.db.collection(JOBS_COLL).doc(jobIdB);
          unsub = jobRef.onSnapshot((snap)=>{
            if (!snap.exists) return;
            const j = snap.data() || {};
            if (j.status === "running") {
              const pct = j.stage === "calling_openai" ? 35 : j.stage === "uploading" ? 80 : 25;
              setBar(i, pct);
              setMeta(i, j.stage === "uploading" ? "Uploading…" : "Generating…");
            }
            if (j.status === "done") {
              if (j.downloadURL) {
                slot.uploadUrl = j.downloadURL;
                slot.imageDataUrl = j.downloadURL;
                setSlotPreview(i, j.downloadURL);
              }
              setBar(i, 100);
              setMeta(i, `Done: ${j.storagePath || ""}`);
              if (unsub) unsub();
            }
            if (j.status === "error") {
              setBar(i, 0);
              setMeta(i, `Error: ${j?.error?.message || "Unknown error"}`);
              if (unsub) unsub();
            }
          });

          await enqueueOpenAIImageJob({
            jobId: jobIdB,
            runId,
            slotIndex: i,
            kind: "edits",
            model,
            prompt: fullPrompt,
            input_storage_path: referenceStoragePath,
            postprocess: {
            finalFrameZoom: FINAL_FRAME_ZOOM,
            anchorX: FINAL_ANCHOR_X,
            anchorY: FINAL_ANCHOR_Y,
          },
            size: "1024x1024",
            quality: "high",
            output_format: "png",
            traits: slot.traits
          });

          return;
        }

        // ---------- Two-pass (has charm macro) ----------
        // Pass A: generate variant WITH pendant (allow larger for detail)
        // Pass B: remove pendant via OpenAI, then post-scale composite (no regen scaling of engraving)

        const planA = charmPlanFromTraits(slot.traits, "placement");
        const promptA = buildPrompt(baseText, slot.traits, true, "placement", planA);

        // OLD multiplier retained ONLY as fallback compatibility for older server code
        const postScale = clamp(1 / CHARM_A_MULT, 0.5, 0.7);

        const removePrompt = [
          "Remove the pendant charm entirely.",
          "Keep the necklace chain, bead stations, clasp, metal tone, model, wardrobe, lighting, and camera exactly the same.",
          "Do not add any new jewelry. Do not change the chain geometry.",
          "Fill the removed area realistically (skin/clothing/background) with matching lighting and texture."
        ].join("\n");

        slot.prompt = `${promptA}\n\n-----\n\n[Pass B: charm_postscale targetPx=${finalCharmTargetPx} (fallbackScale=${postScale.toFixed(3)})]`;

        let passAStoragePath = null;

        // Listen Pass B (final)
        unsubB = jobRefB.onSnapshot((snap) => {
          if (!snap.exists) return;
          const jb = snap.data() || {};

          if (jb.status === "running") {
            const pct =
              jb.stage === "downloading_inputs" ? 62 :
              jb.stage === "removing_charm" ? 70 :
              jb.stage === "postprocessing" ? 82 :
              jb.stage === "uploading" ? 92 :
              jb.stage === "calling_openai" ? 70 :
              65;
            setBar(i, pct);

            const stageLabel =
              jb.stage === "downloading_inputs" ? "Preparing (Pass B)…" :
              jb.stage === "removing_charm" ? "Removing Charm (Pass B)…" :
              jb.stage === "postprocessing" ? "Postprocessing (Pass B)…" :
              jb.stage === "uploading" ? "Uploading (Pass B)…" :
              "Working (Pass B)…";
            setMeta(i, stageLabel);
          }

          if (jb.status === "done") {
            if (unsubB) { unsubB(); unsubB = null; }
            const url = jb.resultUrl || jb.downloadURL || "";
            if (url) {
              // Persist + show final image for this slot (matches Pass A behavior)
              slot.uploadUrl = url;
              slot.imageDataUrl = url;
              setSlotPreview(i, url);
            }            
            setBar(i, 100);
            setMeta(i, "Done");
          }

          if (jb.status === "error") {
            if (unsubB) { unsubB(); unsubB = null; }
            setBar(i, 0);
            setMeta(i, "Error");
            console.error("Pass B error", jb.error);
          }
        });

        // Listen Pass A → when done, enqueue Pass B (non-regenerative post-scale)
        unsubA = jobRefA.onSnapshot((snap) => {
          if (!snap.exists) return;
          const jb = snap.data() || {};

          if (jb.status === "running") {
            const pct =
              jb.stage === "calling_openai" ? 55 :
              jb.stage === "uploading" ? 68 :
              50;
            setBar(i, pct);
            setMeta(i, jb.stage === "uploading" ? "Uploading (Pass A)…" : "Generating (Pass A)…");
          }

          if (jb.status === "done") {
            if (unsubA) { unsubA(); unsubA = null; }

            // Your background function writes these on success:
            // - storagePath (preferred)
            // - downloadURL (but we need storagePath for Pass B input)
            passAStoragePath = jb.storagePath || jb.output_storage_path || null;

            if (!passAStoragePath) {
              setBar(i, 0);
              setMeta(i, "Error");
              console.error("Pass A done but missing storagePath", jb);
              return;
            }

            setBar(i, 70);
            setMeta(i, "Queued (Pass B)…");

            // Enqueue Pass B (non-regenerative post-scale composite)
            enqueueOpenAIImageJob({
              jobId: jobIdB,
              runId,
              slotIndex: i,
              kind: "charm_postscale",
              model,
              input_storage_path: passAStoragePath,
              remove_prompt: removePrompt,
              postprocess: {
                // NEW: stable proportional sizing
                targetPx: finalCharmTargetPx,
                // OLD: kept for backwards compatibility (server ignores if targetPx exists)
                scale: postScale,                
                shadowOpacity: 0.22,
                shadowBlur: 2,
                diffThreshold: 18,
                finalFrameZoom: FINAL_FRAME_ZOOM,
                anchorX: FINAL_ANCHOR_X,
                anchorY: FINAL_ANCHOR_Y
              },
              size: "1024x1024",
              quality: "high",
              output_format: "png",
              traits: slot.traits
            });
          }

          if (jb.status === "error") {
            if (unsubA) { unsubA(); unsubA = null; }
            setBar(i, 0);
            setMeta(i, "Error");
            console.error("Pass A error", jb.error);
          }
        });

        // Enqueue Pass A
        await enqueueOpenAIImageJob({
          jobId: jobIdA,
          runId,
          slotIndex: i,
          kind: "edits",
          model,
          prompt: promptA,
          input_storage_path: referenceStoragePath,
          input_charm_storage_path: charmMacroStoragePath,
          size: "1024x1024",
          quality: "high",
          output_format: "png",
          postprocess: {
              finalFrameZoom: FINAL_FRAME_ZOOM,
              anchorX: FINAL_ANCHOR_X,
              anchorY: FINAL_ANCHOR_Y
            },
          traits: slot.traits
        });
      } catch (e) {
        setBar(i, 0);
        setMeta(i, `Error: ${e.message}`);
        console.error(e);
        if (unsubA) { unsubA(); unsubA = null; }
        if (unsubB) { unsubB(); unsubB = null; }
      }

     }

    async function runPool(items, worker, concurrency = 2) {
      const queue = items.slice();
      const runners = Array.from({ length: concurrency }, async () => {
        while (queue.length) {
          const item = queue.shift();
          await worker(item);
        }
      });
      await Promise.all(runners);
    }

    async function generateEight(){
      statusEl.textContent = "Generating 8…";
      gen8Btn.disabled = true;

      // IMPORTANT: prevents Netlify/OpenAI proxy inactivity timeouts
      // Keep at 2–3 for stability; you still generate 8 total.
      await runPool(slots.map(s => s.i), generateOne, 2);

      gen8Btn.disabled = false;
      statusEl.textContent = "Done";
    }

    // Init
    renderGrid();

    gen8Btn.addEventListener("click", generateEight);
    clearBtn.addEventListener("click", ()=>{
      referenceDataUrl = null;
      referenceStoragePath = null;   // NEW
      referenceDownloadUrl = null;   // NEW
      refNameEl.textContent = "No image selected";
      refPreviewEl.innerHTML = "";
      charmMacroDataUrl = null;
      charmMacroStoragePath = null;
      charmMacroDownloadUrl = null;
      charmNameEl.textContent = "No charm macro selected";
      charmPreviewEl.innerHTML = "";
      charmFileEl.value = "";
      renderGrid();
      statusEl.textContent = "Idle";
      gen8Btn.disabled = false;
    });
  </script>
</body>
</html>